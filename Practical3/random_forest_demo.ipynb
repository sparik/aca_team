{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest and Logistic Regression Prediction Accuracies Comparison\n",
    "We are going to predict diagnostics of cardiac Single Proton Emission Computed Tomography (SPECT) images by splitting the dataset into traingin and test set's. Each of the patients is classified into two categories: normal(specified as 0 in the dataset's first column) and abnormal(specified as 1). Properties are described here https://archive.ics.uci.edu/ml/datasets/SPECTF+Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from decision_tree import DecisionTree\n",
    "from random_forest import RandomForest\n",
    "from logistic_regression import gradient_descent\n",
    "from logistic_regression import sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'SPECTF.dat'\n",
    "data = np.loadtxt(filename, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### printing a sample from the dataset (first and last rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.  72.  62.  69.  67.  78.  82.  74.  65.  69.  63.  70.  70.  72.\n",
      "   74.  70.  71.  72.  75.  66.  65.  73.  78.  74.  79.  74.  69.  69.\n",
      "   70.  71.  69.  72.  70.  62.  65.  65.  71.  63.  60.  69.  73.  67.\n",
      "   71.  56.  58.]\n",
      " [  0.  64.  66.  68.  71.  62.  64.  74.  73.  63.  67.  66.  74.  70.\n",
      "   74.  59.  64.  75.  73.  70.  66.  79.  81.  79.  78.  61.  62.  76.\n",
      "   72.  67.  67.  71.  75.  65.  62.  70.  69.  68.  65.  75.  72.  62.\n",
      "   64.  57.  54.]]\n",
      "(267, 45)\n"
     ]
    }
   ],
   "source": [
    "print(data[[1, -1]])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the below function computes the accuracy of evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_score(Y_true, Y_predict):\n",
    "    accuracy = 0\n",
    "    for i in range(len(Y_true)):\n",
    "        if Y_true[i] == Y_predict[i]:\n",
    "            accuracy = accuracy + 1\n",
    "    return accuracy / len(Y_true) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the main function to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial 1\n",
      "trial 2\n",
      "trial 3\n",
      "trial 4\n",
      "trial 5\n",
      "trial 6\n",
      "trial 7\n",
      "trial 8\n",
      "trial 9\n",
      "trial 10\n",
      "trial 11\n",
      "trial 12\n",
      "trial 13\n",
      "trial 14\n",
      "trial 15\n",
      "trial 16\n",
      "trial 17\n",
      "trial 18\n",
      "trial 19\n",
      "trial 20\n",
      "trial 21\n",
      "trial 22\n",
      "trial 23\n",
      "trial 24\n",
      "trial 25\n",
      "trial 26\n",
      "trial 27\n",
      "trial 28\n",
      "trial 29\n",
      "trial 30\n",
      "trial 31\n",
      "trial 32\n",
      "trial 33\n",
      "trial 34\n",
      "trial 35\n",
      "trial 36\n",
      "trial 37\n",
      "trial 38\n",
      "trial 39\n",
      "trial 40\n",
      "trial 41\n",
      "trial 42\n",
      "trial 43\n",
      "trial 44\n",
      "trial 45\n",
      "trial 46\n",
      "trial 47\n",
      "trial 48\n",
      "trial 49\n",
      "trial 50\n",
      "Random Forest Accuracy =  36.4444444444\n",
      "Logistic Reg. Accuracy =  79.2592592593\n"
     ]
    }
   ],
   "source": [
    "def evaluate_performance():\n",
    "    X = data[:, 1:]\n",
    "    y = np.array([data[:, 0]]).T\n",
    "    n, d = X.shape\n",
    "    all_accuracies_forest = []\n",
    "    all_accuracies_log_reg = []\n",
    "    NUMBER_OF_TREES = 10\n",
    "    MAX_TREE_DEPTH_RF = 100\n",
    "    MAX_TREE_DEPTH_TR = 100\n",
    "    RATIO_PER_TREE = 0.75\n",
    "\n",
    "    for trial in range(50):\n",
    "        print('trial', trial + 1)\n",
    "        idx = np.arange(n)\n",
    "        np.random.seed(13)\n",
    "        np.random.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "        # divide data into train-test\n",
    "        folds, i = 10, 3\n",
    "        Xtest = X[i::folds]  # i::folds = i-th element, (i+folds)th element, ...\n",
    "        ytest = y[i::folds]\n",
    "        Xtrain = np.array([X[j] for j in range(len(X)) if (j % folds) != i])\n",
    "        ytrain = np.array([y[j] for j in range(len(y)) if (j % folds) != i])\n",
    "        train_data = np.column_stack((Xtrain, ytrain))\n",
    "\n",
    "        # train the random forest\n",
    "        classifier_forest = RandomForest(NUMBER_OF_TREES, MAX_TREE_DEPTH_RF, RATIO_PER_TREE)\n",
    "        classifier_forest.fit(train_data)\n",
    "        y_pred_forest = classifier_forest.predict(Xtest)\n",
    "        accuracy_forest = accuracy_score(ytest, np.array(y_pred_forest))\n",
    "        all_accuracies_forest.append(accuracy_forest)\n",
    "\n",
    "        # train by logistic regression\n",
    "        beta = gradient_descent(np.column_stack((np.ones(len(Xtrain)),Xtrain)), ytrain, max_steps=5)\n",
    "        y_pred_log_reg = []\n",
    "        for i in range(Xtest.shape[0]):\n",
    "            sigm = sigmoid((np.column_stack((np.ones(len(Xtest)), Xtest))).dot(beta))\n",
    "            if sigm[i] >= 0.5:\n",
    "                y_pred_log_reg.append(1)\n",
    "            else:\n",
    "                y_pred_log_reg.append(0)\n",
    "        accuracy_log_reg = accuracy_score(ytest, np.array(y_pred_log_reg))\n",
    "        all_accuracies_log_reg.append(accuracy_log_reg)\n",
    "\n",
    "    meanRandomForestAccuracy = np.mean(all_accuracies_forest)\n",
    "    stddevRandomForestAccuracy = np.std(all_accuracies_forest)\n",
    "\n",
    "    meanLogisticRegressionAccuracy = np.mean(all_accuracies_log_reg)\n",
    "    stddevLogisticRegressionAccuracy = np.std(all_accuracies_log_reg)\n",
    "\n",
    "    stats = np.zeros(2)\n",
    "    stats[0] = meanRandomForestAccuracy\n",
    "    stats[1] = meanLogisticRegressionAccuracy\n",
    "    return stats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stats = evaluate_performance()\n",
    "    print(\"Random Forest Accuracy = \", stats[0])\n",
    "    print(\"Logistic Reg. Accuracy = \", stats[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
